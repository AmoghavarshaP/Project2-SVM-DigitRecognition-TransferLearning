{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##The premise of this project is for the implementation a CNN with VGG-16 as a feature selector \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an ImageGenerator object that is used to randomize and make certain small transformations to the image\n",
    "#to build better and robust networks\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rotation_range=30,\n",
    "                              width_shift_range=0.1,\n",
    "                              height_shift_range=0.1,\n",
    "                              rescale=1/255,\n",
    "                              zoom_range=0.2,\n",
    "                              shear_range=0.2,\n",
    "                              fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f406ea55da0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406ea00438> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406ea00fd0> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f406c175748> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406c17d7f0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406c17d080> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f406c185dd8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406c18ba90> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406c18fa20> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406c18fe80> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f406c19a160> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406c19d828> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406c19da90> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406c19af98> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f406e1ce128> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406c1a1e80> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406f247b70> True\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f406f280080> True\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f406f263518> True\n",
      "<tensorflow.python.keras.layers.pooling.GlobalMaxPooling2D object at 0x7f406f2c3dd8> True\n"
     ]
    }
   ],
   "source": [
    "model = vgg16.VGG16(weights='imagenet', include_top=False, \n",
    "                    input_shape=(150,150,3), pooling=\"max\")\n",
    "\n",
    "for layer in model.layers[:-5]:\n",
    "        layer.trainable = False\n",
    "\n",
    "for layer in model.layers:\n",
    "    print(layer, layer.trainable)\n",
    "\n",
    "\n",
    "transfer_model = Sequential()\n",
    "for layer in model.layers:\n",
    "    transfer_model.add(layer)\n",
    "transfer_model.add(Dense(128, activation=\"relu\"))  \n",
    "transfer_model.add(Dropout(0.5))\n",
    "transfer_model.add(Dense(10, activation=\"softmax\")) \n",
    "\n",
    "adam = optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.00001)\n",
    "\n",
    "transfer_model.compile(loss=\"categorical_crossentropy\",\n",
    "                      optimizer=adam,\n",
    "                      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 150, 150, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 150, 150, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 75, 75, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 75, 75, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 75, 75, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 37, 37, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 37, 37, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 37, 37, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 18, 18, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 18, 18, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 18, 18, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 9, 9, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 9, 9, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling2d (Global (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 14,781,642\n",
      "Trainable params: 7,146,378\n",
      "Non-trainable params: 7,635,264\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = '/home/amoghavarsha/Project_CNN/my_project_env/Dataset/training/training'\n",
    "validation_directory = '/home/amoghavarsha/Project_CNN/my_project_env/Dataset/validation/validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1098 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "## Getting the training and the validation sets\n",
    "batch_size = 16\n",
    "train_gen = image_gen.flow_from_directory(train_directory,target_size=(150,150),batch_size=batch_size,\n",
    "                                         class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 272 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_gen = image_gen.flow_from_directory(validation_directory,target_size=(150,150),batch_size=batch_size,\n",
    "                                         class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoghavarsha/Project_CNN/my_project_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "68/68 [==============================] - 253s 4s/step - loss: 2.5558 - accuracy: 0.1123 - val_loss: 1.9113 - val_accuracy: 0.4338\n",
      "Epoch 2/30\n",
      "68/68 [==============================] - 252s 4s/step - loss: 1.8870 - accuracy: 0.3353 - val_loss: 1.4465 - val_accuracy: 0.5331\n",
      "Epoch 3/30\n",
      "68/68 [==============================] - 256s 4s/step - loss: 1.4549 - accuracy: 0.4746 - val_loss: 0.8776 - val_accuracy: 0.6985\n",
      "Epoch 4/30\n",
      "68/68 [==============================] - 250s 4s/step - loss: 0.8281 - accuracy: 0.7227 - val_loss: 0.7860 - val_accuracy: 0.7574\n",
      "Epoch 5/30\n",
      "68/68 [==============================] - 250s 4s/step - loss: 0.5977 - accuracy: 0.8173 - val_loss: 0.9970 - val_accuracy: 0.6691\n",
      "Epoch 6/30\n",
      "68/68 [==============================] - 245s 4s/step - loss: 0.5871 - accuracy: 0.8230 - val_loss: 0.7683 - val_accuracy: 0.7757\n",
      "Epoch 7/30\n",
      "68/68 [==============================] - 245s 4s/step - loss: 0.3718 - accuracy: 0.8865 - val_loss: 0.7216 - val_accuracy: 0.7941\n",
      "Epoch 8/30\n",
      "68/68 [==============================] - 246s 4s/step - loss: 0.3204 - accuracy: 0.9066 - val_loss: 0.5291 - val_accuracy: 0.8309\n",
      "Epoch 9/30\n",
      "68/68 [==============================] - 152s 2s/step - loss: 0.3082 - accuracy: 0.9007 - val_loss: 0.6030 - val_accuracy: 0.8088\n",
      "Epoch 10/30\n",
      "68/68 [==============================] - 158s 2s/step - loss: 0.2266 - accuracy: 0.9223 - val_loss: 0.4515 - val_accuracy: 0.8456\n",
      "Epoch 11/30\n",
      "68/68 [==============================] - 161s 2s/step - loss: 0.1627 - accuracy: 0.9490 - val_loss: 0.6601 - val_accuracy: 0.8199\n",
      "Epoch 12/30\n",
      "68/68 [==============================] - 158s 2s/step - loss: 0.2379 - accuracy: 0.9181 - val_loss: 0.7025 - val_accuracy: 0.8346\n",
      "Epoch 13/30\n",
      "68/68 [==============================] - 156s 2s/step - loss: 0.1980 - accuracy: 0.9337 - val_loss: 0.4873 - val_accuracy: 0.8382\n",
      "Epoch 14/30\n",
      "68/68 [==============================] - 151s 2s/step - loss: 0.1014 - accuracy: 0.9697 - val_loss: 0.5351 - val_accuracy: 0.8603\n",
      "Epoch 15/30\n",
      "68/68 [==============================] - 151s 2s/step - loss: 0.1247 - accuracy: 0.9607 - val_loss: 0.5029 - val_accuracy: 0.8640\n",
      "Epoch 16/30\n",
      "68/68 [==============================] - 151s 2s/step - loss: 0.0784 - accuracy: 0.9732 - val_loss: 0.5161 - val_accuracy: 0.8713\n",
      "Epoch 17/30\n",
      "68/68 [==============================] - 150s 2s/step - loss: 0.0661 - accuracy: 0.9824 - val_loss: 0.7837 - val_accuracy: 0.8015\n",
      "Epoch 18/30\n",
      "68/68 [==============================] - 150s 2s/step - loss: 0.1425 - accuracy: 0.9592 - val_loss: 0.4858 - val_accuracy: 0.8529\n",
      "Epoch 19/30\n",
      "68/68 [==============================] - 149s 2s/step - loss: 0.1098 - accuracy: 0.9651 - val_loss: 0.5255 - val_accuracy: 0.8640\n",
      "Epoch 20/30\n",
      "68/68 [==============================] - 148s 2s/step - loss: 0.0890 - accuracy: 0.9778 - val_loss: 0.4731 - val_accuracy: 0.8676\n",
      "Epoch 21/30\n",
      "68/68 [==============================] - 149s 2s/step - loss: 0.0427 - accuracy: 0.9922 - val_loss: 0.5521 - val_accuracy: 0.8603\n",
      "Epoch 22/30\n",
      "68/68 [==============================] - 149s 2s/step - loss: 0.0373 - accuracy: 0.9896 - val_loss: 0.4826 - val_accuracy: 0.8971\n",
      "Epoch 23/30\n",
      "68/68 [==============================] - 150s 2s/step - loss: 0.0333 - accuracy: 0.9902 - val_loss: 0.6864 - val_accuracy: 0.8750\n",
      "Epoch 24/30\n",
      "68/68 [==============================] - 151s 2s/step - loss: 0.0620 - accuracy: 0.9817 - val_loss: 0.6866 - val_accuracy: 0.8235\n",
      "Epoch 25/30\n",
      "68/68 [==============================] - 153s 2s/step - loss: 0.1613 - accuracy: 0.9532 - val_loss: 0.8847 - val_accuracy: 0.7757\n",
      "Epoch 26/30\n",
      "68/68 [==============================] - 150s 2s/step - loss: 0.1058 - accuracy: 0.9718 - val_loss: 0.6786 - val_accuracy: 0.8603\n",
      "Epoch 27/30\n",
      "68/68 [==============================] - 151s 2s/step - loss: 0.0508 - accuracy: 0.9866 - val_loss: 0.6815 - val_accuracy: 0.8456\n",
      "Epoch 28/30\n",
      "68/68 [==============================] - 160s 2s/step - loss: 0.0356 - accuracy: 0.9944 - val_loss: 0.5947 - val_accuracy: 0.8566\n",
      "Epoch 29/30\n",
      "68/68 [==============================] - 151s 2s/step - loss: 0.0559 - accuracy: 0.9814 - val_loss: 0.6423 - val_accuracy: 0.8750\n",
      "Epoch 30/30\n",
      "68/68 [==============================] - 151s 2s/step - loss: 0.0215 - accuracy: 0.9954 - val_loss: 0.6507 - val_accuracy: 0.8603\n"
     ]
    }
   ],
   "source": [
    "results = transfer_model.fit_generator(train_gen,epochs=30,steps_per_epoch=1097//batch_size,\n",
    "                              validation_data=validation_gen,validation_steps=272//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.save('TL_CNN_Monkey.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amoghavarsha/Project_CNN/my_project_env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "_, acc = transfer_model.evaluate_generator(validation_gen, steps=272 //batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing accuracy for the CNN with the 10-Species-Monkey dataset is : 84.559\n"
     ]
    }
   ],
   "source": [
    "print('The testing accuracy for the CNN with the 10-Species-Monkey dataset is : %.3f' % (acc * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "x = keras.models.load_model('TL_CNN_Monkey.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
